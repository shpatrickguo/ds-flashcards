---
name: Statistical Power in Hypothesis Testing
tags: statistics, hypothesis-testing, statistical-power
---

## Q: What is statistical power in hypothesis testing?

## Answer (Technical)

Statistical power is the probability that a test correctly rejects the null hypothesis when a specific alternative is true (i.e., detects a true effect). It is defined as 1 − β, where β is the probability of a Type II error (failing to detect a real effect).

Power depends on:
- Sample size (larger sample → higher power)
- Effect size (larger true effects → higher power)
- Significance level α (a higher α makes it easier to detect effects, increasing power)
- Data variability (more variability → lower power)

Typical practice is to plan studies with at least 80% power, though some fields use 90%.

## Answer (Non-Technical)

Think of power as how good a test is at "spotting" a real difference when it exists. If your test has 80% power, it will find 8 out of 10 real effects of the specified size. Low-power studies frequently miss real effects and can waste resources.

Example: If you want to know whether a new treatment improves recovery by a certain amount, planning the study to have 80% or 90% power ensures a high chance you’ll notice that improvement if it really exists.
